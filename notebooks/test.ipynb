{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction interface for Cog\n",
    "from cog import BasePredictor, Input, Path\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import subprocess\n",
    "from PIL import Image, ImageFilter\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from diffusers import (\n",
    "    DDIMScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    HeunDiscreteScheduler,\n",
    "    PNDMScheduler,\n",
    "    FluxPriorReduxPipeline,\n",
    "    FluxFillPipeline,\n",
    ")\n",
    "\n",
    "from script.download_weights import download_weights\n",
    "\n",
    "\n",
    "MODEL_NAME_FILL = \"black-forest-labs/FLUX.1-Fill-dev\"\n",
    "MODEL_NAME_REDUX = \"black-forest-labs/FLUX.1-Redux-dev\"\n",
    "MODEL_CACHE = \"checkpoints\"\n",
    "# https://github.com/replicate/cog-flux/blob/main/weights.py#L208-L224\n",
    "MODELS_URL_FILL = \"https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev/resolve/main/flux1-fill-dev.safetensors\"\n",
    "MODELS_URL_REDUX = \"https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev/resolve/main/flux1-redux-dev.safetensors\"\n",
    "\n",
    "SCHEDULERS = {\n",
    "    \"DDIM\": DDIMScheduler,\n",
    "    \"DPMSolverMultistep\": DPMSolverMultistepScheduler,\n",
    "    \"HeunDiscrete\": HeunDiscreteScheduler,\n",
    "    \"K_EULER_ANCESTRAL\": EulerAncestralDiscreteScheduler,\n",
    "    \"K_EULER\": EulerDiscreteScheduler,\n",
    "    \"PNDM\": PNDMScheduler,\n",
    "}\n",
    "\n",
    "\n",
    "def login_huggingface():\n",
    "    load_dotenv()\n",
    "    login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "\n",
    "class Predictor(BasePredictor):\n",
    "    def setup(self) -> None:\n",
    "        \"\"\"Load the model into memory to make running multiple predictions efficient\"\"\"\n",
    "        print(\"Downloading weights\")\n",
    "        login_huggingface()\n",
    "        if not os.path.exists(MODEL_CACHE):\n",
    "            download_weights()\n",
    "        print(\"Loading Flux Prior Redux\")\n",
    "        self.pipe_prior_redux = FluxPriorReduxPipeline.from_pretrained(\n",
    "            \"black-forest-labs/FLUX.1-Redux-dev\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            cache_dir=MODEL_CACHE,\n",
    "        ).to(\"cuda\")\n",
    "        print(\"Loading Flux Fill\")\n",
    "        self.pipe = FluxFillPipeline.from_pretrained(\n",
    "            \"black-forest-labs/FLUX.1-Fill-dev\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            cache_dir=MODEL_CACHE,\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "    def scale_down_image(self, image_path: Path, max_size: int) -> Image.Image:\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        scaling_factor = min(max_size / width, max_size / height)\n",
    "        new_width = int(width * scaling_factor)\n",
    "        new_height = int(height * scaling_factor)\n",
    "        resized_image = image.resize((new_width, new_height))\n",
    "        cropped_image = self.crop_center(resized_image)\n",
    "        return cropped_image\n",
    "\n",
    "    def crop_center(self, pil_img):\n",
    "        img_width, img_height = pil_img.size\n",
    "        crop_width = self.base(img_width)\n",
    "        crop_height = self.base(img_height)\n",
    "        return pil_img.crop(\n",
    "            (\n",
    "                (img_width - crop_width) // 2,\n",
    "                (img_height - crop_height) // 2,\n",
    "                (img_width + crop_width) // 2,\n",
    "                (img_height + crop_height) // 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def base(self, x):\n",
    "        return int(8 * math.floor(int(x) / 8))\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        image: Path = Input(description=\"Input image\"),\n",
    "        mask: Path = Input(\n",
    "            description=\"Mask image - make sure it's the same size as the input image\"\n",
    "        ),\n",
    "        reference_image: Path = Input(\n",
    "            description=\"Reference image - image to encode as input for Flux.1 Redux\"\n",
    "        ),\n",
    "        prompt: str = Input(\n",
    "            description=\"Input prompt\",\n",
    "            default=\"cartoon of a black woman laughing, digital art\",\n",
    "        ),\n",
    "        scheduler: str = Input(\n",
    "            description=\"scheduler\",\n",
    "            choices=list(SCHEDULERS.keys()),\n",
    "            default=\"K_EULER\",\n",
    "        ),\n",
    "        guidance_scale: float = Input(\n",
    "            description=\"Guidance scale\", ge=0, le=10, default=8.0\n",
    "        ),\n",
    "        steps: int = Input(\n",
    "            description=\"Number of denoising steps\", ge=1, le=80, default=20\n",
    "        ),\n",
    "        strength: float = Input(\n",
    "            description=\"1.0 corresponds to full destruction of information in image\",\n",
    "            ge=0.01,\n",
    "            le=1.0,\n",
    "            default=0.7,\n",
    "        ),\n",
    "        seed: int = Input(\n",
    "            description=\"Random seed. Leave blank to randomize the seed\", default=None\n",
    "        ),\n",
    "        num_outputs: int = Input(\n",
    "            description=\"Number of images to output. Higher number of outputs may OOM.\",\n",
    "            ge=1,\n",
    "            le=4,\n",
    "            default=1,\n",
    "        ),\n",
    "        blur_radius: int = Input(\n",
    "            description=\"Standard deviation of the Gaussian kernel for the mask. Higher values will blur the mask more.\",\n",
    "            ge=0,\n",
    "            le=128,\n",
    "            default=16,\n",
    "        ),\n",
    "        prompt_embeds_scale: float = Input(\n",
    "            description=\"Strength of prompt embeddings on Flux Redux\",\n",
    "            ge=0.01,\n",
    "            le=2.0,\n",
    "            default=1.0,\n",
    "        ),\n",
    "        pooled_prompt_embeds_scale: float = Input(\n",
    "            description=\"Strength of pooled prompt embeddings on Flux Redux\",\n",
    "            ge=0.01,\n",
    "            le=2.0,\n",
    "            default=1.0,\n",
    "        ),\n",
    "    ) -> List[Path]:\n",
    "        \"\"\"Run a single prediction on the model\"\"\"\n",
    "        # Configure Seed\n",
    "        if seed is None:\n",
    "            seed = int.from_bytes(os.urandom(2), \"big\")\n",
    "        print(f\"Using seed: {seed}\")\n",
    "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "\n",
    "        # Configure Scheduler\n",
    "        self.pipe.scheduler = SCHEDULERS[scheduler].from_config(\n",
    "            self.pipe.scheduler.config\n",
    "        )\n",
    "\n",
    "        # Configure Input Image\n",
    "        input_image = self.scale_down_image(image, 1024)\n",
    "\n",
    "        # Configure Mask Image\n",
    "        pil_mask = Image.open(mask)\n",
    "        mask_image = pil_mask.resize((input_image.width, input_image.height))\n",
    "        mask_image = mask_image.filter(ImageFilter.GaussianBlur(blur_radius))\n",
    "\n",
    "        # Run Flux Prior Redux\n",
    "        pipe_prior_output = self.pipe_prior_redux(\n",
    "            image=reference_image,\n",
    "            prompt=[prompt] * num_outputs if prompt is not None else None,\n",
    "            prompt_embeds_scale=prompt_embeds_scale,\n",
    "            pooled_prompt_embeds_scale=pooled_prompt_embeds_scale,\n",
    "        )\n",
    "        prompt_embeds = pipe_prior_output[\"prompt_embeds\"]\n",
    "        pooled_prompt_embeds = pipe_prior_output[\"pooled_prompt_embeds\"]\n",
    "\n",
    "        # Run Flux Fill\n",
    "        result = self.pipe(\n",
    "            prompt_embeds=prompt_embeds,\n",
    "            pooled_prompt_embeds=pooled_prompt_embeds,\n",
    "            image=input_image,\n",
    "            mask_image=mask_image,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=steps,\n",
    "            strength=strength,\n",
    "            generator=generator,\n",
    "            width=input_image.width,\n",
    "            height=input_image.height,\n",
    "        )\n",
    "\n",
    "        # Save Output Images\n",
    "        output_paths = []\n",
    "        for i, output in enumerate(result.images):\n",
    "            output_path = f\"/tmp/out-{i}.png\"\n",
    "            output.save(output_path)\n",
    "            output_paths.append(Path(output_path))\n",
    "\n",
    "        return output_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b33027a524c441bacce2e90eba9c620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db11c99a88a84120a60d156c99e1a19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151d6d3bb8e74948bfc510532661dd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/857M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16ed872473c43cda7324a651ca6c4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_embedder/config.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbc580e85904debb69c725fcf04c2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f958bf714f3a41b4be264c5900898ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_encoder/config.json:   0%|          | 0.00/419 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260cda11219445028dda6e78869a2b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/129M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8600820ad208439e835838e477dd816f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdf1c6182254d5b95f6e0b1052c6471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a708f821394b8da20049d10d51e554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 23 files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536cf3c794104355b65eccd4f803f4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/299 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e1f2a2bdf34a9eba6c2ba1847a4a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0360b392544815b8d5c798bbfa4d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b46610b7be4228baa8c602d8e5caed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)t_encoder_2/model.safetensors.index.json:   0%|          | 0.00/19.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bf9d610261422f8df7dd74a82ceeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d384d58889c94517b04840ccc3ef1cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb05a7b7ef14e8f9b0c84b21174ccba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da305c37bb354ceca310448aa5402bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd741ca5e67d40598e0ceb359583a400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7384b50fa244f0b46a19a65d45ee4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132cf62de37845d18319b27407e2ebcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a018ebf5fac24888b8b03d28e950b25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b522dc1d5f1464e994c8e1e68e48c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8120533cdfd4ce0a270cef4d26a6c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816fb62ea5324576bd686b09c9869763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)pytorch_model-00001-of-00003.safetensors:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb2cb480926442491fd4ddef36d2d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c115fd3d2fb4c378f46c2825c21878c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/config.json:   0%|          | 0.00/393 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6941c8b83ac4362af404cdd21c2e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)pytorch_model-00002-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5e564e467040dca48fd0a6ccf026e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)pytorch_model-00003-of-00003.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b23b35526e14034848e59b0913f2478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ion_pytorch_model.safetensors.index.json:   0%|          | 0.00/121k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125ff01584e240b2b613008fe0e264ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/774 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e11e16eb248e4ad842bc2558a1d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cog.types import Path\n",
    "\n",
    "# override MODEL_CACHE to point to the correct directory\n",
    "MODEL_CACHE = \"../checkpoints\"\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = Predictor()\n",
    "predictor.setup()\n",
    "\n",
    "# Define paths for required images\n",
    "input_image = Path(\"images/cartoon-man-laughing.png\")\n",
    "mask_image = Path(\"images/mask.png\")  # You'll need to create a mask image\n",
    "reference_image = Path(\"images/cartoon-man-laughing.png\")  # Using same image as reference\n",
    "\n",
    "# Run prediction with default parameters\n",
    "results = predictor.predict(\n",
    "    image=input_image,\n",
    "    mask=mask_image,\n",
    "    reference_image=reference_image,\n",
    "    prompt=\"cartoon of a black woman laughing, digital art\",\n",
    "    num_outputs=1\n",
    ")\n",
    "\n",
    "display(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cog-flux-fill-redux-dev-xKz1zol3-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
